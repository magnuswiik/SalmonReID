{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract every 5th image from sequence of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Videoer/GP010022/\"\n",
    "to_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Videoer/Annoteringsklar_GP010022/\"\n",
    "\n",
    "# Gather JPEG image files corresponding to each JSON file\n",
    "imgs = sorted(file for file in os.listdir(from_path) if file.endswith('.jpg'))\n",
    "\n",
    "every_5th_img = imgs[::5]\n",
    "    \n",
    "for img in every_5th_img:\n",
    "    shutil.copy(from_path + img, to_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract subset of data from Labelme annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Videoer/Annoteringsklar_GP010022/\"\n",
    "to_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Videoer/Annotert_GP010022/\"\n",
    "\n",
    "# Gather JSON annotation files\n",
    "annots = sorted(file for file in os.listdir(from_path) if file.endswith('.json'))\n",
    "# Gather JPEG image files corresponding to each JSON file\n",
    "imgs = sorted(file for file in os.listdir(from_path) if file.endswith('.jpg') and file[:-4] + '.json' in annots)\n",
    "\n",
    "for annot in annots:\n",
    "    shutil.copy(from_path + annot, to_data_data_data_data_data_data_data_data_data_data_path)\n",
    "    \n",
    "for img in imgs:\n",
    "    shutil.copy(from_path + img, to_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change names on all files in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Videoer/Annotert_GP010022/\"\n",
    "\n",
    "# Gather JSON annotation files\n",
    "annots = sorted(file for file in os.listdir(path) if file.endswith('.json'))\n",
    "# Gather JPEG image files corresponding to each JSON file\n",
    "imgs = sorted(file for file in os.listdir(path) if file.endswith('.jpg') and file[:-4] + '.json' in annots)\n",
    "\n",
    "for index, file in enumerate(annots):\n",
    "    os.rename(os.path.join(path, file), os.path.join(path, \"GP010022_\" + file))\n",
    "\n",
    "for index, file in enumerate(imgs):\n",
    "    os.rename(os.path.join(path, file), os.path.join(path, \"GP010022_\" + file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move Images to Images folder and Annotations to Boxes folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Videoer/Annotert_GP010022/\"\n",
    "to_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Helfisk_Deteksjonssett/\"\n",
    "\n",
    "# Gather JSON annotation files\n",
    "annots = sorted(file for file in os.listdir(from_path) if file.endswith('.json'))\n",
    "# Gather JPEG image files corresponding to each JSON file\n",
    "imgs = sorted(file for file in os.listdir(from_path) if file.endswith('.jpg') and file[:-4] + '.json' in annots)\n",
    "\n",
    "\n",
    "for annot in annots:\n",
    "    shutil.copy(from_path + annot, to_path + \"Boxes/\")\n",
    "    \n",
    "for img in imgs:\n",
    "    shutil.copy(from_path + img, to_path + \"Images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if all annotation files contains shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "data_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_kroppsdeler_Deteksjonssett/\"\n",
    "\n",
    "items = os.listdir(data_path)\n",
    "\n",
    "# Filter out only the folders from the list of items\n",
    "folders = [item for item in items if os.path.isdir(os.path.join(data_path, item)) and item != 'old']\n",
    "\n",
    "for folder in folders:\n",
    "    \n",
    "    folder_path = os.path.join(data_path, folder)\n",
    "    \n",
    "    annots = sorted(file for file in os.listdir(folder_path) if file.endswith('.json'))\n",
    "    \n",
    "    for i in range(len(annots)):\n",
    "        \n",
    "        annot_path = os.path.join(folder_path, annots[i])\n",
    "\n",
    "        with open(annot_path, 'r') as file:\n",
    "            content = json.load(file)\n",
    "            shapes = content['shapes']\n",
    "            sh = len(shapes)\n",
    "            if len(shapes) == 0:\n",
    "                print(annots[i] + \" is empty...\")\n",
    "                '''img_path = annot_path[:-4] + \"jpg\"\n",
    "                os.remove(annot_path)\n",
    "                os.remove(img_path)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find files with head shape in annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fish5_GP020101_00008324.json', 'fish5_GP020101_00008539.json', 'fish5_GP020101_00009864.json', 'fish5_GP020101_00013589.json', 'fish3_GOPR0101_00021666.json', 'fish3_GP010101_00002126.json', 'fish3_GP020101_00000574.json', 'fish3_GP020101_00005399.json', 'fish3_GP020101_00010549.json', 'fish3_GP020101_00015304.json', 'fish3_GP020101_00015784.json', 'fish20_GOPR0101_00007728.json', 'fish20_GOPR0101_00007806.json', 'fish20_GP010022_00001980.json', 'fish20_GP010022_00002035.json', 'fish20_GP010022_00002180.json', 'fish19_GOPR0101_00001767.json', 'fish19_GOPR0101_00002733.json', 'fish19_GOPR0101_00003759.json', 'fish19_GP010022_00011890.json', 'fish19_GP010022_00022440.json', 'fish17_GP010101_00005971.json', 'fish17_GP010101_00006132.json', 'fish17_GP010101_00007113.json', 'fish10_GP020101_00009304.json', 'fish10_GP020101_00009474.json', 'fish10_GP020101_00021234.json', 'fish7_GOPR0101_00010335.json', 'fish7_GOPR0101_00016812.json', 'fish7_GOPR0101_00018327.json', 'fish7_GOPR0101_00018411.json', 'fish7_GOPR0101_00018795.json', 'fish7_GP020101_00025319.json', 'fish9_GOPR0101_00001626.json', 'fish9_GOPR0101_00001815.json', 'fish9_GOPR0101_00019212.json', 'fish9_GP020101_00005884.json']\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "data_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_kroppsdeler_Deteksjonssett/\"\n",
    "\n",
    "items = os.listdir(data_path)\n",
    "\n",
    "# Filter out only the folders from the list of items\n",
    "folders = [item for item in items if os.path.isdir(os.path.join(data_path, item)) and item != 'old']\n",
    "\n",
    "files = []\n",
    "\n",
    "for folder in folders:\n",
    "    \n",
    "    folder_path = os.path.join(data_path, folder)\n",
    "    \n",
    "    annots = sorted(file for file in os.listdir(folder_path) if file.endswith('.json'))\n",
    "    \n",
    "    for i in range(len(annots)):\n",
    "        \n",
    "        annot_path = os.path.join(folder_path, annots[i])\n",
    "\n",
    "        with open(annot_path, 'r') as file:\n",
    "            content = json.load(file)\n",
    "            shapes = content['shapes']\n",
    "            for shape in shapes:\n",
    "                if shape['label'] == 'head':\n",
    "                    files.append(annots[i])\n",
    "                    \n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop images whole salmon from Labelme Json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Helfisk_Deteksjonssett/\"\n",
    "to_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Helfisk_Landmark_Deteksjonssett/\"\n",
    "\n",
    "from_img = \"GP020101_00012069.jpg\"\n",
    "from_json = \"GP020101_00012069.json\"\n",
    "\n",
    "annots = sorted(file for file in os.listdir(from_path + \"Boxes/\") if file.endswith('.json'))\n",
    "imgs = sorted(file for file in os.listdir(from_path + \"Images/\") if file.endswith('.jpg'))\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "\n",
    "    with open(from_path + \"Boxes/\" + annots[i], 'r') as file:\n",
    "        img = cv2.imread(from_path + \"Images/\" + imgs[i], cv2.IMREAD_COLOR)\n",
    "        content = json.load(file)\n",
    "        shapes = content['shapes']\n",
    "        \n",
    "        for shape in shapes:\n",
    "            box = shape['points']\n",
    "            x1 = int(box[0][0])\n",
    "            y1 = int(box[0][1])\n",
    "            x2 = int(box[1][0])\n",
    "            y2 = int(box[1][1])\n",
    "            id = shape['group_id']\n",
    "            cropped_image = img[y1:y2, x1:x2, :]\n",
    "            \n",
    "            if not os.path.isdir(to_path + \"fish\" + str(id)):\n",
    "                os.mkdir(to_path + \"fish\" + str(id))\n",
    "                \n",
    "            filename = to_path + 'fish' + str(id) + '/fish' + str(id) + \"_\"  + imgs[i]\n",
    "            cv2.imwrite(filename, cropped_image)\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop images landmarks from Labelme annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_kroppsdeler_Deteksjonssett/\"\n",
    "to_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_kroppsdeler_Identifikasjonssett/\"\n",
    "\n",
    "annots = []\n",
    "imgs = []\n",
    "\n",
    "for folder in os.listdir(from_path):\n",
    "    if (not folder.startswith('.')) and os.path.isdir(os.path.join(from_path, folder)):\n",
    "        for file in sorted(os.listdir(os.path.join(from_path, folder))):\n",
    "            if file.endswith('.json'):\n",
    "                annots.append(file)\n",
    "        for file in sorted(os.listdir(os.path.join(from_path, folder))):\n",
    "            if file.endswith(('.jpg', '.jpeg', '.png')) and file[:-4] + '.json' in annots:\n",
    "                imgs.append(file)\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    with open(from_path + annots[i].split('_')[0] + \"/\" + annots[i], 'r') as file:\n",
    "        img = cv2.imread(from_path + annots[i].split('_')[0] + \"/\" + imgs[i], cv2.IMREAD_COLOR)\n",
    "        content = json.load(file)\n",
    "        shapes = content['shapes']\n",
    "        \n",
    "        for shape in shapes:\n",
    "            if shape['shape_type'] == 'rectangle':\n",
    "                box = shape['points']\n",
    "                x1 = int(box[0][0])\n",
    "                y1 = int(box[0][1])\n",
    "                x2 = int(box[1][0])\n",
    "                y2 = int(box[1][1])\n",
    "                fish = imgs[i].split('_')[0]\n",
    "                landmark = shape['label']\n",
    "                cropped_image = img[y1:y2, x1:x2, :]\n",
    "                \n",
    "                if not os.path.isdir(to_path):\n",
    "                    os.makedirs(to_path)\n",
    "                    \n",
    "                filepath = os.path.join(to_path, fish + \"_\" + landmark + imgs[i][imgs[i].find(\"_\"):])\n",
    "                cv2.imwrite(filepath, cropped_image)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train and test set with selected image frames in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "import shutil, os, random\n",
    "\n",
    "data_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_kroppsdeler_Identifikasjonssett/\"\n",
    "path_train = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_kroppsdeler_Identifikasjonssett/Train\"\n",
    "path_validation = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_kroppsdeler_Identifikasjonssett/Validation\"\n",
    "path_test = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_kroppsdeler_Identifikasjonssett/Test\"\n",
    "\n",
    "if not os.path.isdir(path_train):\n",
    "    os.makedirs(path_train)\n",
    "if not os.path.isdir(path_validation):\n",
    "    os.makedirs(path_validation)\n",
    "if not os.path.isdir(path_test):\n",
    "    os.makedirs(path_test)\n",
    "\n",
    "individuals = {\n",
    "    'fish3': {\n",
    "        'trainvideo': {\n",
    "            'id': ['GOPR0101'],\n",
    "            'count': 0},\n",
    "        'testvideo': {\n",
    "            'id': ['GP020101'],\n",
    "            'count': 0},\n",
    "},\n",
    "    'fish5': {\n",
    "        'trainvideo': {\n",
    "            'id': ['GOPR0101'],\n",
    "            'count': 0},\n",
    "        'testvideo': {\n",
    "            'id': ['GP020101'],\n",
    "            'count': 0},\n",
    "},\n",
    "    'fish7': {\n",
    "        'trainvideo': {\n",
    "            'id': ['GOPR0101'],\n",
    "            'count': 0},\n",
    "        'testvideo': {\n",
    "            'id': ['GP020101'],\n",
    "            'count': 0},\n",
    "},\n",
    "    'fish9': {\n",
    "        'trainvideo': {\n",
    "            'id': ['GOPR0101'],\n",
    "            'count': 0},\n",
    "        'testvideo': {\n",
    "            'id': ['GP020101'],\n",
    "            'count': 0},\n",
    "},\n",
    "    'fish10': {\n",
    "        'trainvideo': {\n",
    "            'id': ['GP020101'],\n",
    "            'count': 0},\n",
    "        'testvideo': {\n",
    "            'id': ['GP010101', 'GOPR0101'],\n",
    "            'count': 0},\n",
    "},\n",
    "    'fish17': {\n",
    "        'trainvideo': {\n",
    "            'id': ['GOPR0101'],\n",
    "            'count': 0},\n",
    "        'testvideo': {\n",
    "            'id': ['GP010101'],\n",
    "            'count': 0},\n",
    "},\n",
    "    'fish19': {\n",
    "        'trainvideo': {\n",
    "            'id': ['GOPR0101'],\n",
    "            'count': 0},\n",
    "        'testvideo': {\n",
    "            'id': ['GP010022'],\n",
    "            'count': 0},\n",
    "},\n",
    "    'fish20': {\n",
    "        'trainvideo': {\n",
    "            'id': ['GP010022'],\n",
    "            'count': 0},\n",
    "        'testvideo': {\n",
    "            'id': ['GOPR0101'],\n",
    "            'count': 0},\n",
    "}\n",
    "}\n",
    "\n",
    "bodyparts = ['eyeregion', 'pectoralfin', 'thorax', 'dorsalfin', 'tailfin']\n",
    "added_files = []\n",
    "\n",
    "dataset_files = os.listdir(data_path)\n",
    "random.shuffle(dataset_files)\n",
    "\n",
    "validation = 0\n",
    "\n",
    "for file in dataset_files:\n",
    "    if not file.startswith('.'):\n",
    "        if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            fish = file[:file.find(\"_\")]\n",
    "            bodypart = file.split(\"_\")[1]\n",
    "            video = file.split(\"_\")[2]\n",
    "            file_path = os.path.join(data_path, file)\n",
    "            if fish in individuals.keys():\n",
    "                if video in individuals[fish]['trainvideo']['id'] and individuals[fish]['trainvideo']['count'] < 50 and file not in added_files:\n",
    "                    global to_path\n",
    "                    if validation == 0:\n",
    "                        to_path = path_train\n",
    "                        validation += 1\n",
    "                    else: \n",
    "                        to_path = path_validation\n",
    "                        validation -= 1\n",
    "                    for bodypart in bodyparts:\n",
    "                        last_slice = file[file.find(\"_\", 8):]\n",
    "                        file_to_add = fish + \"_\" + bodypart + last_slice\n",
    "                        file_to_add_path = os.path.join(data_path, file_to_add)\n",
    "                        if not os.path.exists(file_to_add_path):\n",
    "                            print(file_to_add_path)\n",
    "                        shutil.copy(file_to_add_path, to_path)\n",
    "                        added_files.append(file_to_add)\n",
    "                    individuals[fish]['trainvideo']['count'] += 1\n",
    "                if video in individuals[fish]['testvideo']['id'] and individuals[fish]['testvideo']['count'] < 10 and file not in added_files:\n",
    "                    for bodypart in bodyparts:\n",
    "                        last_slice = file[file.find(\"_\", 8):]\n",
    "                        file_to_add = fish + \"_\" + bodypart + last_slice\n",
    "                        file_to_add_path = os.path.join(data_path, file_to_add)\n",
    "                        if not os.path.exists(file_to_add_path):\n",
    "                            print(file_to_add_path)\n",
    "                        shutil.copy(file_to_add_path, path_test)\n",
    "                        added_files.append(file_to_add)\n",
    "                    individuals[fish]['testvideo']['count'] += 1\n",
    "                    \n",
    "print('finished')               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count videos per fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fish2': ['GP020101'],\n",
       " 'fish5': ['GOPR0101', 'GP020101'],\n",
       " 'fish12': ['GP020101'],\n",
       " 'fish3': ['GOPR0101', 'GP010101', 'GP020101'],\n",
       " 'fish14': ['GP020101'],\n",
       " 'fish20': ['GOPR0101', 'GP010022'],\n",
       " 'fish6': ['GP020101'],\n",
       " 'fish19': ['GOPR0101', 'GP010022'],\n",
       " 'fish17': ['GOPR0101', 'GP010101'],\n",
       " 'fish10': ['GOPR0101', 'GP010101', 'GP020101'],\n",
       " 'fish7': ['GOPR0101', 'GP020101'],\n",
       " 'fish9': ['GOPR0101', 'GP020101']}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from_path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_kroppsdeler_Deteksjonssett/\"\n",
    "\n",
    "annots = []\n",
    "imgs = []\n",
    "\n",
    "for folder in os.listdir(from_path):\n",
    "    if (not folder.startswith('.')) and os.path.isdir(os.path.join(from_path, folder)):\n",
    "        for file in sorted(os.listdir(os.path.join(from_path, folder))):\n",
    "            if file.endswith('.json'):\n",
    "                annots.append(file)\n",
    "        for file in sorted(os.listdir(os.path.join(from_path, folder))):\n",
    "            if file.endswith(('.jpg', '.jpeg', '.png')) and file[:-4] + '.json' in annots:\n",
    "                imgs.append(file)\n",
    "\n",
    "\n",
    "videos_per_fish = {\n",
    "}\n",
    "\n",
    "for annot in annots:\n",
    "    fish = annot.split('_')[0]\n",
    "    video = annot.split('_')[1]\n",
    "    if fish not in videos_per_fish.keys():\n",
    "        videos_per_fish[fish] = [video]\n",
    "    else:\n",
    "        if video not in videos_per_fish[fish]:\n",
    "            videos_per_fish[fish].append(video)\n",
    "\n",
    "videos_per_fish\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Helfisk_Deteksjonssett/debug/edit/\"\n",
    "\n",
    "files = sorted(os.listdir(path))\n",
    "\n",
    "for file in files:\n",
    "    oldname = os.path.join(path,file)\n",
    "    newname = os.path.join(path, \"GP010101_\" + file)\n",
    "    os.rename(oldname, newname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate test set for step 1 and 2 based on step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GOPR0101_00007683.jpg', 'GOPR0101_00007698.jpg', 'GOPR0101_00007707.jpg', 'GOPR0101_00007716.jpg', 'GOPR0101_00007728.jpg', 'GOPR0101_00007734.jpg', 'GOPR0101_00007740.jpg', 'GOPR0101_00007812.jpg', 'GOPR0101_00007824.jpg', 'GOPR0101_00017205.jpg', 'GOPR0101_00017220.jpg', 'GOPR0101_00017232.jpg', 'GP010022_00011590.jpg', 'GP010022_00011595.jpg', 'GP010022_00011890.jpg', 'GP010022_00011910.jpg', 'GP010022_00012105.jpg', 'GP010022_00012110.jpg', 'GP010022_00013995.jpg', 'GP010022_00014005.jpg', 'GP010022_00014100.jpg', 'GP010022_00014120.jpg', 'GP010101_00004999.jpg', 'GP010101_00005003.jpg', 'GP010101_00005008.jpg', 'GP010101_00005013.jpg', 'GP010101_00005025.jpg', 'GP010101_00005049.jpg', 'GP010101_00005057.jpg', 'GP010101_00005971.jpg', 'GP010101_00006132.jpg', 'GP010101_00007113.jpg', 'GP010101_00008216.jpg', 'GP010101_00008223.jpg', 'GP010101_00008231.jpg', 'GP010101_00008236.jpg', 'GP010101_00008252.jpg', 'GP010101_00008258.jpg', 'GP010101_00008263.jpg', 'GP020101_00000574.jpg', 'GP020101_00005399.jpg', 'GP020101_00005499.jpg', 'GP020101_00005539.jpg', 'GP020101_00005879.jpg', 'GP020101_00005884.jpg', 'GP020101_00005889.jpg', 'GP020101_00005914.jpg', 'GP020101_00005919.jpg', 'GP020101_00008349.jpg', 'GP020101_00008379.jpg', 'GP020101_00008519.jpg', 'GP020101_00008539.jpg', 'GP020101_00008569.jpg', 'GP020101_00009864.jpg', 'GP020101_00010549.jpg', 'GP020101_00013569.jpg', 'GP020101_00013574.jpg', 'GP020101_00013589.jpg', 'GP020101_00013599.jpg', 'GP020101_00015254.jpg', 'GP020101_00015259.jpg', 'GP020101_00015264.jpg', 'GP020101_00015289.jpg', 'GP020101_00015294.jpg', 'GP020101_00015304.jpg', 'GP020101_00015324.jpg', 'GP020101_00015334.jpg', 'GP020101_00015344.jpg', 'GP020101_00015349.jpg', 'GP020101_00015429.jpg', 'GP020101_00015759.jpg', 'GP020101_00015769.jpg', 'GP020101_00015784.jpg']\n",
      "73\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "import json, os, shutil\n",
    "path3 = \"/Users/magnuswiik/Documents/NTNU/5.klasse/Masteroppgave/masterthesis/testset.json\"\n",
    "\n",
    "with open(path3, 'r') as file:\n",
    "    testset = json.load(file)\n",
    "\n",
    "test_images = []\n",
    "test_annots = []\n",
    "\n",
    "for image in testset['testset']:\n",
    "    first_occurrence = image.find(\"_\")\n",
    "    second_occurrence = image.find(\"_\", first_occurrence + 1)+1\n",
    "    image = image[second_occurrence:]\n",
    "    test_images.append(image)\n",
    "    annot = image[:-3] + \"json\"\n",
    "    test_annots.append(annot)\n",
    "    \n",
    "source1 = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_Deteksjonssett/Images/\"\n",
    "source2 = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_Deteksjonssett/Boxes/\"\n",
    "\n",
    "images = [file for file in sorted(os.listdir(source1)) if file in test_images]\n",
    "annots = [file for file in sorted(os.listdir(source2)) if file in test_annots]\n",
    "\n",
    "print(images)\n",
    "print(len(annots))\n",
    "\n",
    "target1 = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_Deteksjonssett/pipeline_images/\"\n",
    "target2 = \"/Users/magnuswiik/prosjektoppgave_data/Masteroppgave_data/Laks_Deteksjonssett/pipeline_annots/\"\n",
    "\n",
    "\n",
    "def copy_files(files, source_dir, target_dir):\n",
    "    for file in files:\n",
    "        src_path = os.path.join(source_dir, file)\n",
    "        dst_path = os.path.join(target_dir, file)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "        print(f'Copied {file} to {target_dir}')\n",
    "\n",
    "# Copy images\n",
    "#copy_files(images, source1, target1)\n",
    "\n",
    "# Copy annotations\n",
    "#copy_files(annots, source2, target2)\n",
    "\n",
    "images = [file for file in sorted(os.listdir(target1)) if file in test_images]\n",
    "print(len(images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fisketrening",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
